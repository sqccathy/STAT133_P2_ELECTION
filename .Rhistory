# Chunk 1
create2004 = FALSE
create2008 = FALSE
create2012 = FALSE
create2016 = FALSE
createGML = FALSE
createCensus = FALSE
# Chunk 2
# Code by Menglu Cao
cNamesManip = function(cNames) {
# Convert	all	county names to lower case
cNames = tolower(cNames)
# Remove symbols in county names
cNames = gsub("[ '%]", "", cNames)
cNames = gsub("-", "", cNames)
cNames = gsub("\n", "", cNames)
# Change & to and in county names
cNames = gsub("&", "and", cNames)
# Remove redundant characters from county names
cNames = gsub("county|parish|reporting|municipality|municipio|censusarea", "", cNames)
# Eliminate	.	from county names
cNames = gsub("\\.", "", cNames)
# Remove digits
cNames = gsub("[0-9]", "", cNames)
}
# Chunk 3
require(readr)
countyVotes2004 = read.delim("http://www.stat.berkeley.edu/~nolan/data/voteProject/countyVotes2004.txt", sep = "")
# Chunk 4
# Split state names and county names
names = strsplit(as.character(countyVotes2004$countyName), split = ",")
# State names
sNames = sapply(names, function(x) x[1])
# Add manipulated state names to the data frame
countyVotes2004$State = tolower(gsub(" ", "", sNames))
# County names
cNames = sapply(names, function(x) x[2])
# Add county names to the data frame
countyVotes2004$County = cNamesManip(cNames)
# Subset countyVotes2004, such that it consists of 4 variables: county names, state names, number of votes for Bush and Kerry
countyVotes2004 = countyVotes2004[, c(5, 4, 2, 3)]
# Change variable names in the data frame
names(countyVotes2004)[c(3, 4)] = c("BushVote2004", "KerryVote2004")
# Chunk 5
# Scrape data of votes in Virginia from HTML tables
require(XML)
require(RCurl)
wikiURL = "https://en.wikipedia.org/wiki/United_States_presidential_election_in_Virginia,_2004"
pageContents = getURLContent(wikiURL)
# Set up XPath to find the table
pDoc = htmlParse(pageContents)
pRoot = xmlRoot(pDoc)
cTable = getNodeSet(pRoot,
"//table/tr/td/a[@title='Accomack County, Virginia']/../../..")
nrows = xmlSize(cTable[[1]])
# Extract Values into Character Matrix
tableChar = do.call(rbind, sapply(1:nrows, function(i) {
strsplit(xmlValue(cTable[[1]][[i]]), "\n")}))
# Names of counties and the states they belong in Virginia
names = tableChar[-1, 1]
counties = names[!grepl(",", names)]
independentCity = c(sapply(strsplit(names[grepl(",", names)], split = ","),
function(x) paste0(x[1], "city")))
# County names
cNames = cNamesManip(c(counties, independentCity))
# Create a character vector consisting of "virginia"
sNames = rep("virginia", length(names))
# Number of votes for Bush & Kerry
BushVote2004 = as.numeric(gsub(",", "", tableChar[-1, 5]))
KerryVote2004 = as.numeric(gsub(",", "", tableChar[-1, 3]))
# Create a data frame for Virginia
Virginia2004 = data.frame(County = cNames, State = sNames, BushVote2004, KerryVote2004)
# Add data of votes in Virginia to countyVotes2004
countyVotes2004 = rbind(countyVotes2004, Virginia2004)
# Chunk 6
summary(countyVotes2004$BushVote2004)
# Chunk 7
countyVotes2004[which(countyVotes2004$BushVote2004 ==
min(countyVotes2004$BushVote2004)), ]
# Chunk 8
countyVotes2004[which(countyVotes2004$BushVote2004 ==                                                 max(countyVotes2004$BushVote2004)), ]
# Chunk 9
# Summary statistics of number of votes for Mccain
summary(countyVotes2004$KerryVote2004)
# Check if the minimum and maximum are reasonable
countyVotes2004[which(countyVotes2004$KerryVote2004 ==
min(countyVotes2004$KerryVote2004)), ]
countyVotes2004[which(countyVotes2004$KerryVote2004 ==                                                max(countyVotes2004$KerryVote2004)), ]
# Chunk 10
save(countyVotes2004, file = "countyVotes2004.rda")
# Chunk 11
load("countyVotes2004.rda")
# Chunk 12
library(xlsx)
wb = loadWorkbook("countyVotes2008.xlsx")
sheets = getSheets(wb)
# Get state names
sNames = tolower(gsub(" ", "", names(sheets)))[-1]
# Import xlsx file into a list.Notice the first sheet is the result of the state level, so I ignore it.
list = lapply(seq(2, 51), function(x) read.xlsx("countyVotes2008.xlsx", x, header = FALSE)[-1, ])
# Repeat state names to match the county names
num_of_county = sapply(list, nrow)
sNames = rep(sNames, num_of_county)
# County names
cNames = cNamesManip(unlist(sapply(list, function(x) x[[1]])))
#get votes for Obama and Mccain from the list
Obama = as.numeric(as.character(unlist(sapply(list, function(x) x[[4]]))))
Mccain = as.numeric(as.character(unlist(sapply(list, function(x) x[[5]]))))
#combine county,state,obamavotes and Mccain votes into a dataframe.
countyVotes2008 = data.frame(County = cNames, State = sNames, ObamaVote2008 = Obama, MccainVote2008 = Mccain)
# Chunk 13
summary(countyVotes2008$ObamaVote2008)
# Chunk 14
countyVotes2008[which(is.na(countyVotes2008$ObamaVote2008)), ]
# Chunk 15
countyVotes2008 = countyVotes2008[!is.na(countyVotes2008$ObamaVote2008), ]
# Chunk 16
countyVotes2008[which(countyVotes2008$ObamaVote2008 == 8), ]
# Chunk 17
summary(countyVotes2008$MccainVote2008)
# Chunk 18
save(countyVotes2008, file = "countyVotes2008.rda")
# Chunk 19
load("~/Downloads/countyVotes2008.rda")
# Chunk 20
require(XML)
# Get state names
sNames_df = read.csv("http://www.stat.berkeley.edu/users/nolan/data/voteProject/countyVotes2012/stateNames.txt")
sNames = tolower(gsub(" ", "", as.vector(sNames_df$states)))
# Drop Alaska from sNames
sNames = sNames[sNames != "alaska"]
# Chunk 21
# Create a vector consisting of all the websites we are going to use
xml2012 = paste0("http://www.stat.berkeley.edu/users/nolan/data/voteProject/countyVotes2012/", sNames, ".xml")
# Get a list of the xml file of each website
xmlList = lapply(xml2012, xmlParse)
# Extract the desired information from each xml file
Obama = lapply(xmlList, function(x) {
xpathSApply(xmlRoot(x), "//abbr[@title =    'Democratic']/../../td[@class='results-popular']", xmlValue)
})
Romney = lapply(xmlList, function(x) {
xpathSApply(xmlRoot(x), "//abbr[@title = 'Republican']/../../td[@class='results-popular']", xmlValue)
})
cNames = lapply(xmlList, function(x) {
xpathSApply(xmlRoot(x), "/table/tbody/tr/th[@class = 'results-county']", xmlValue)
})
# Convert the lists to numeric vectors
ObamaVote2012 = as.numeric(gsub("[, ]", "", unlist(Obama)))
RomneyVote2012 = as.numeric(gsub("[, ]", "", unlist(Romney)))
# County names
cNames = cNamesManip(unlist(cNames))
# Repeat state names to match county names
sNames = rep(sNames, sapply(Obama, length))
# Create a data frame with four columns, namely County, State, ObamaVote2012 and RomneyVote2012
countyVotes2012 = data.frame(County = cNames, State = sNames, ObamaVote2012, RomneyVote2012)
# Chunk 22
summary(countyVotes2012$ObamaVote2012)
# Chunk 23
countyVotes2012[which(countyVotes2012$ObamaVote2012 ==
min(countyVotes2012$ObamaVote2012)), ]
# Chunk 24
summary(countyVotes2012$RomneyVote2012)
# Chunk 25
save(countyVotes2012, file = "countyVotes2012.rda")
# Chunk 26
load("countyVotes2012.rda")
# Chunk 27
require(readr)
countyVotes2016 = read.csv("http://www.stat.berkeley.edu/users/nolan/data/voteProject/2016_US_County_Level_Presidential_Results.csv")
countyVotes2016$county_name = cNamesManip(countyVotes2016$county_name)
# We keep the FIPS, in order to merge with other data sources; we also keep numbers of votes for Clinton and Trump, and the state abbreviations and county names for further data cleaning
countyVotes2016 = countyVotes2016[, c(10, 9, 2, 3, 11)]
names(countyVotes2016)[c(3, 4, 5)] = c("ClintonVote2016", "TrumpVote2016", "FIPS")
# Chunk 28
summary(countyVotes2016$ClintonVote2016)
# Chunk 29
countyVotes2016[which(countyVotes2016$ClintonVote2016 ==
min(countyVotes2016$ClintonVote2016)), ]
# Chunk 30
summary(countyVotes2016$TrumpVote2016)
# Chunk 31
countyVotes2016 = countyVotes2016[!countyVotes2016$state_abbr == "AK", ]
# Chunk 32
save(countyVotes2016, file = "countyVotes2016.rda")
# Chunk 33
load("countyVotes2016.rda")
# Chunk 34
require(XML)
GML = xmlParse("http://www.stat.berkeley.edu/users/nolan/data/voteProject/counties.gml")
doc = xmlRoot(GML)
# Get county names
cNames = cNamesManip(as.character(xpathSApply(doc, "//county/gml:name", xmlValue)))
# Get state names
sNames = as.character(xpathSApply(doc, "//state/gml:name", xmlValue))
sNames = tolower(gsub(" |\n", "", sNames))
# Get the number of counties in each state
num_of_county = xpathSApply(doc, "//state", xmlSize) - 1
# Repeat state names so that they correspond to counties
sNames = rep(sNames, num_of_county)
# Get the longitude and latitude of counties. Note that the coordinates have values in the millions, so we divide them by 10^6 to derive the right values
Longitude = as.numeric(xpathSApply(doc, "/doc/state/county/gml:location/gml:coord/gml:X", xmlValue)) / 10^6
Latitude = as.numeric(xpathSApply(doc, "/doc/state/county/gml:location/gml:coord/gml:Y", xmlValue)) / 10^6
# Chunk 35
GML_df = data.frame(County = cNames, State = sNames, Latitude, Longitude, stringsAsFactors = FALSE)
# Chunk 36
require(ggplot2)
ggplot(data = GML_df) +
geom_point(mapping = aes(x = Longitude, y = Latitude, size = 0.2, alpha = 0.5)) +
scale_x_continuous(name = "Longitude") +
scale_y_continuous(name = "Latitude") +
labs(title = "Map of counties in the United States") +
theme_bw()
# Chunk 37
save(GML_df, file = "GML.rda")
# Chunk 38
load("GML.rda")
# Chunk 39
# POPULATION DATA
B01003 = read.csv("http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/B01003.csv")
summary(B01003)
# TOTAL POPULATION
totalPopFrame = B01003[B01003$POPGROUP.id == 1,
c("GEO.id2", "GEO.display.label",
"HD01_VD01")] #Frame to extract total population
totalPopFrame$totalPop = totalPopFrame$HD01_VD01 #1 Generate total population variable
totalPopFrame = totalPopFrame[ , c("GEO.id2", "GEO.display.label",
"totalPop")] # Subset to exclude HD01_VD01
summary(totalPopFrame)
# WHITE POPULATION
whitePopFrame = B01003[B01003$POPGROUP.id == 2,
c("GEO.id2", "GEO.display.label", "HD01_VD01")] # Frame to extract white population
whitePopFrame$whitePop = whitePopFrame$HD01_VD01 #2 Generate white population variable
whitePopFrame = whitePopFrame[ , c("GEO.id2", "GEO.display.label",
"whitePop")] # Subset to exclude HD01_VD01
summary(whitePopFrame)
# MERGE INDIVIDUAL POPULATION DATA FILES
populationData = merge(x = totalPopFrame, y = whitePopFrame,
by = c("GEO.id2", "GEO.display.label"),
all = TRUE)
# GENERATE PERCENT WHITE VARIABLE
## (There are too many missing counties for a black proportion variable, but this allows for comparisons between white/non-white, at least.)
populationData$percentWhite =
100 * (populationData$whitePop / populationData$totalPop) #3 White population as a percent of total population
summary(populationData)
# Chunk 40
# FAMILY STRUCTURE
DP02 = read.csv("http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/DP02.csv")
summary(DP02)
# FRAME CONSTRUCTION
familyData = DP02[ , c("GEO.id2", "GEO.display.label",
"HC03_VC06", "HC03_VC07",
"HC03_VC08", "HC03_VC09",
"HC03_VC10", "HC03_VC11",
"HC03_VC12", "HC03_VC13",
"HC03_VC14", "HC03_VC15",
"HC03_VC17", "HC03_VC18",
"HC01_VC21", "HC03_VC36",
"HC03_VC37")]
summary(familyData)
# VARIABLES
familyData$familiesWithKids = DP02$HC03_VC06 #4 Percent of households that are families of any kind with own hildren under 18
familyData$marriedcouples = DP02$HC03_VC07 #5 Percent of households that are married couples
familyData$marriedWithChildren = DP02$HC03_VC08 #6 Percent of households that are married couples with own children under 18
familyData$maleHouseholder = DP02$HC03_VC09 #7 Percent of households with a male householder and no wife present
familyData$singleDads = DP02$HC03_VC10 #8 Percent households with a single male head of household with own children under 18
familyData$femaleHouseholder = DP02$HC03_VC11 #9 Percent of households with a female householder and no husband present
familyData$singleMoms = DP02$HC03_VC12 #10 Percent of households with a single female head of household with own children under 18
familyData$nonFamilyHouseholds = DP02$HC03_VC13 #11 Percent of households that are non-family households
familyData$livingAlone = DP02$HC03_VC14 #12 Percent of households that are householders living alone
familyData$seniorsLivingAlone = DP02$HC03_VC15 #13 Percent housholder living alone, 65 years old or over
familyData$youthHouseholds = DP02$HC03_VC17 #14 Percent households with at least one person under 18
familyData$seniorHouseholds = DP02$HC03_VC18 #15 Percent households with at least one person over 65
familyData$avgFamilySize = DP02$HC01_VC21 #16 Average size of families
familyData$neverMarriedMen = DP02$HC03_VC36 #17 Percent of males 15 and older who have never married (not inc. divorced or separated)
familyData$marriedMen = DP02$HC03_VC37 #18 Percent of males 15 and older who are married (currently married, not inc. separated)
# SUBSET DATA FRAME
familyData = familyData[ , c(1:2, 18:32)]
summary(familyData)
# MERGE FAMILY DATA WITH POPULATION DATA
famPopData = merge(x = populationData, y = familyData,
by = c("GEO.id2", "GEO.display.label"),
all = TRUE)
summary(famPopData)
# Chunk 41
# EMPLOYMENT DATA
DP03 = read.csv("http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/DP03.csv")
summary(DP03)
# FRAME CONSTRUCTION
employmentData = DP03[ , c("GEO.id2", "GEO.display.label",
"HC03_VC06", "HC03_VC08",
"HC03_VC17", "HC03_VC18",
"HC03_VC41", "HC03_VC42",
"HC03_VC50", "HC03_VC51",
"HC03_VC52", "HC03_VC54",
"HC03_VC58")]
summary(employmentData)
# VARIABLES
# GENERAL EMPLOYMENT
employmentData$laborForce = DP03$HC03_VC06 #19 Labor Force Participation Rate (percent over 16 years old who are employed or unemployed)
employmentData$unemployed = DP03$HC03_VC08 #20 Unemployment Rate (percent over 16 unemployed)
employmentData$femaleLaborForce = DP03$HC03_VC17 #21 Female labor force participation rate (percent of females over 16 who are employed or unemployed)
employmentData$employedWomen = DP03$HC03_VC18 #22 Women over 16 who are employed
employmentData$femaleUnemployment =
(employmentData$femaleLaborForce - employmentData$employedWomen) #23 Female Unemployment Rate as the difference between the female labor force participation rate and the rate of female employment
# EMPLOYMENT BY OCCUPATION
employmentData$occManagement = DP03$HC03_VC41 #24 Pecent of the civilian labor force employed in management, business, science, and arts occupations
employmentData$occService = DP03$HC03_VC42 #25 Percent of the civilian labor force employed in service occupations
# EMPLOYMENT BY INDUSTRY
employmentData$extractiveIndustries = DP03$HC03_VC50 #26 Percent of the civilian labor force employed in agriculture, forestry, fishing and hunting, and mining industries
employmentData$constructionIndustry = DP03$HC03_VC51 #27 Percent of the civilian labor force employed in the construction industry
employmentData$manufacturingIndustry = DP03$HC03_VC52 #28 Percent of the civilian labor force employed in the manufacturing industry
employmentData$retailIndustry = DP03$HC03_VC54 #29 Percent of the civilian labor force employed in the retail trade industry
employmentData$professionalIndustries = DP03$HC03_VC58 #30 Percent of the civilian labor force employed in Professional, scientific, and management, and administrative and waste management services industries
# SUBSET DATA FRAME
employmentData = employmentData[ , c(1:2, 14:25)]
summary(employmentData)
# Chunk 42
# MERGE EMPLOYMENT DATA WITH POPULATION AND FAMILY DATA
censusData = merge(x = famPopData, y = employmentData,
by = c("GEO.id2", "GEO.display.label"),
all = TRUE)
summary(censusData)
# STATE & COUNTY NAMES
cNames = as.character(censusData$GEO.display.label)
cNames = gsub(' ', "", cNames)
# SPLIT STATE NAMES AND COUNTY NAMES
names = strsplit(cNames, split = ",")
# ADD COUNTY NAMES TO THE DATA FRAME
censusData$County = cNamesManip(sapply(names, function(x) x[1]))
# ADD STATE NAMES TO THE DATA FRAME
censusData$State = tolower(gsub(" ", "", sapply(names, function(x) x[2])))
names(censusData)[1] = "FIPS"
censusData = censusData[, -2]
summary(censusData)
save(censusData, file = "censusData.rda")
# Chunk 43
load("censusData.rda")
# Chunk 44
merge0812 = merge(countyVotes2012,countyVotes2008, by = c("County", "State"), all = TRUE)
merge0812[which(!complete.cases(merge0812)), ]
# Chunk 45
merge0812[which(merge0812$County == "districtofcolumbia"), c(5,6)] = c(245800, 17367)
merge0812 = merge0812[(which(!merge0812$County %in% c("alaska"))), ]
finalDataFrame = merge0812
# Chunk 46
mergeGMLCensus = merge(GML_df, censusData, by.x = c("County", "State"), all = TRUE)
# Chunk 47
mergeGMLCensus[!complete.cases(mergeGMLCensus),]
mergeGMLCensus = mergeGMLCensus[(which(!mergeGMLCensus$State %in% c("puertorico", "alaska"))), ]
mergeGMLCensus = mergeGMLCensus[(which(!mergeGMLCensus$County %in% c("king", "loving", "kenedy", "cliftonforgecity", "southbostoncity"))), ]
mergeGMLCensus[mergeGMLCensus$County == "broomfield", c(3,4)] = c(39.953302, -105.052038)
mergeGMLCensus = mergeGMLCensus[(which(!mergeGMLCensus$County == "donaana")), ]
mergeGMLCensus[mergeGMLCensus$County == "do\xfc\xbe\x8c\x96\x98\xbcaana",  c("County", "Latitude", "Longitude")] = c("donaana", 32.34523, -106.83238)
# Chunk 48
merge04GMLCensus = merge(mergeGMLCensus, countyVotes2004, by = c("County", "State"), all = TRUE)
# Chunk 49
merge04GMLCensus[!complete.cases(merge04GMLCensus),]
merge04GMLCensus = merge04GMLCensus[(which(!merge04GMLCensus$County %in% c("king", "loving", "kenedy"))), ]
merge04GMLCensus = merge04GMLCensus[(which(!merge04GMLCensus$State == "hawaii")), ]
# Chunk 50
merge04GMLCensus16 = merge(countyVotes2016[, c("ClintonVote2016", "TrumpVote2016", "FIPS")], merge04GMLCensus, by = "FIPS", all = TRUE)
merge04GMLCensus16[!complete.cases(merge04GMLCensus16),]
b = merge04GMLCensus16[!complete.cases(merge04GMLCensus16),]
View(b)
View(b)
merge0812[which(merge0812$County == "districtofcolumbia"), c(5,6)] = c(245800, 17367)
merge0812 = merge0812[(which(!merge0812$County %in% c("alaska"))), ]
finalDataFrame = merge0812
merge0812 = merge(countyVotes2012,countyVotes2008, by = c("County", "State"), all = TRUE)
merge0812[which(!complete.cases(merge0812)), ]
load("countyVotes2008.rda")
merge0812 = merge(countyVotes2012,countyVotes2008, by = c("County", "State"), all = TRUE)
merge0812[which(!complete.cases(merge0812)), ]
merge0812[which(merge0812$County == "districtofcolumbia"), c(5,6)] = c(245800, 17367)
merge0812 = merge0812[(which(!merge0812$County %in% c("alaska"))), ]
finalDataFrame = merge0812
c = merge(merge04GMLCensus16,merge0812,by = c("County", "State"), all = TRUE)
View(c)
View(c)
d = c[!complete.cases(c)]
d = c[!complete.cases(c),]
View(d)
View(d)
View(countyVotes2004)
View(countyVotes2004)
# Create a vector consisting of all the websites we are going to use
xml2012 = paste0("http://www.stat.berkeley.edu/users/nolan/data/voteProject/countyVotes2012/", sNames, ".xml")
# Get a list of the xml file of each website
xmlList = lapply(xml2012, xmlParse)
# Extract the desired information from each xml file
Obama = lapply(xmlList, function(x) {
xpathSApply(xmlRoot(x), "//abbr[@title =    'Democratic']/../../td[@class='results-popular']", xmlValue)
})
Romney = lapply(xmlList, function(x) {
xpathSApply(xmlRoot(x), "//abbr[@title = 'Republican']/../../td[@class='results-popular']", xmlValue)
})
cNames = lapply(xmlList, function(x) {
xpathSApply(xmlRoot(x), "/table/tbody/tr/th[@class = 'results-county']", xmlValue)
})
# Convert the lists to numeric vectors
ObamaVote2012 = as.numeric(gsub("[, ]", "", unlist(Obama)))
RomneyVote2012 = as.numeric(gsub("[, ]", "", unlist(Romney)))
# County names
cNames = cNamesManip(unlist(cNames))
# Repeat state names to match county names
sNames = rep(sNames, sapply(Obama, length))
# Create a data frame with four columns, namely County, State, ObamaVote2012 and RomneyVote2012
countyVotes2012 = data.frame(County = cNames, State = sNames, ObamaVote2012, RomneyVote2012)
load("countyVotes2012.rda")
View(countyVotes2012)
View(countyVotes2012)
sNames = rep(sNames, sapply(Obama, length))
sNames = gsub("-", "", sNames)
# Create a data frame with four columns, namely County, State, ObamaVote2012 and RomneyVote2012
countyVotes2012 = data.frame(County = cNames, State = sNames, ObamaVote2012, RomneyVote2012)
View(merge0812)
View(merge0812)

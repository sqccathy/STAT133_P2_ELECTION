---
title: "Election Project"
Author: Menglu Cao, Jieni Wan, Qichen Sun, John Towey, Victor Choi
output: html_document
---

```{r}
create2004 = FALSE
create2008 = FALSE
create2012 =FALSE
create2016 = FALSE
createGML = FALSE
createCensus = FALSE
```

### STEP 1: DATA WRANGLING

## Election Results in 2004 (By Menglu Cao)
```{r eval = create2004}
  require(readr)
  countyVotes2004 = read.delim("http://www.stat.berkeley.edu/~nolan/data/voteProject/countyVotes2004.txt", sep = "")
  
  # Split state names and county names
  names = strsplit(as.character(countyVotes2004$countyName), split = ",")
  
  # State names
  sNames = sapply(names, function(x) x[1])
  
  # Remove blanks in state names
  sNames = gsub(" ", "", sNames)
  
  # Add State names to the data frame
  countyVotes2004$State = sNames
  
  # County names
  cNames = sapply(names, function(x) x[2])
  
  # Apply regular expressions and string munipulations to county names
  # Convert	all	county names to lower case
  cNames = tolower(cNames)
  # Remove blanks in county names
  cNames = gsub(" ", "", cNames)
  # Change & to and in county names
  cNames = gsub("&", "and", cNames)
  # Remove county or parish from county names
  cNames = gsub("county|parish", "", cNames)
  # Eliminate	.	from county names
  cNames = gsub("\\.", "", cNames)
  
  # Add county names to the data frame
  countyVotes2004$County = cNames
  
  # Subset countyVotes2004, such that it consists of 4 variables: county names, state names, number of votes for Bush and Kerry
  countyVotes2004 = countyVotes2004[, c(5, 4, 2, 3)]
  
  # Change variable names in the data frame
  names(countyVotes2004)[c(3, 4)] = c("BushVote2004", "KerryVote2004")
  
  # Scrape data of votes in Virginia from HTML tables
  require(XML)
  require(RCurl)
  wikiURL = "https://en.wikipedia.org/wiki/United_States_presidential_election_in_Virginia,_2004"
  pageContents = getURLContent(wikiURL)
  
  # Set up XPath to find the table
  pDoc = htmlParse(pageContents)
  pRoot = xmlRoot(pDoc)
  cTable = getNodeSet(pRoot, 
            "//table/tr/td/a[@title='Accomack County, Virginia']/../../..")
  nrows = xmlSize(cTable[[1]])
  
  # Extract Values into	Character	Matrix
  tableChar = do.call(rbind, sapply(1:nrows, function(i) {
                  strsplit(xmlValue(cTable[[1]][[i]]), "\n")}))
  
  # Names of counties in Virginia
  cNames = tableChar[-1, 1]
  
  # Apply regular expressions and string munipulations to county names
  cNames = tolower(cNames)
  cNames = gsub(" ", "", cNames)
  cNames = gsub("&", "and", cNames)
  cNames = gsub("county|parish", "", cNames)
  cNames = gsub("\\.", "", cNames)
  
  # Create a character vector consisting of "virginia"
  sNames = rep("virginia", length(cNames))
  
  # Number of votes for Bush & Kerry
  BushVote2004 = as.numeric(gsub(",", "", tableChar[-1, 5]))
  KerryVote2004 = as.numeric(gsub(",", "", tableChar[-1, 3]))
  
  # Create a data frame for Virginia
  Virginia2004 = data.frame(County = cNames, State = sNames, BushVote2004, KerryVote2004)
  
  # Add data of votes in Virginia to countyVotes2004
  countyVotes2004 = rbind(countyVotes2004, Virginia2004)
  
  # EDA of the data
  # Summary Statistics of number of votes for Bush
  summary(countyVotes2004$BushVote2004)
  #    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  #      65    2946    6367   19160   16080  954800 
  
  # Check if the minimum is reasonable
  countyVotes2004[which(countyVotes2004$BushVote2004 ==
                        min(countyVotes2004$BushVote2004)), ]
  #      County State BushVote2004 KerryVote2004
  # 2587 loving texas           65            12
  # The min occurs in Loving, Texas. According to Wikipedia, as of the 2010 census, its population was 82, making it the least populous county in the United States. Thus the minimum being 54 makes sense.
  
  # Check if the maximum is reasonable
  countyVotes2004[which(countyVotes2004$BushVote2004 == max(countyVotes2004$BushVote2004)), ]
  #         County      State BushVote2004 KerryVote2004
  # 176 losangeles california       954764       1670341
  
  # The max occurs in Los Angeles, California. According to Wikipedia, the 2010 United States Census reported that Los Angeles had a population of 3,792,621. Thus the maximum being 954764 makes sense.
  
  # Summary statistics of number of votes for Mccain
  summary(countyVotes2004$KerryVote2004)
  # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  #   12    1782    4048   18060   10550 1670000
  
  # Check if the minimum and maximum are reasonable
  countyVotes2004[which(countyVotes2004$KerryVote2004 ==
                        min(countyVotes2004$KerryVote2004)), ]
  #      County State BushVote2004 KerryVote2004
  # 2587 loving texas           65            12

  countyVotes2004[which(countyVotes2004$KerryVote2004 == max(countyVotes2004$KerryVote2004)), ]
  #         County      State BushVote2004 KerryVote2004
  # 176 losangeles california       954764       1670341
  
  # According to the explanation for the max and min for votes for Bush, the maximum and minimum here make sense as well
  
  save(countyVotes2004, file = "countyVotes2004.rda")
```

```{r}
  load("countyVotes2004.rda")
```

## Election Results in 2008 (BY Qichen Sun)
```{r eval = create2008}
  library(xlsx)
  wb = loadWorkbook("countyVotes2008.xlsx")
  sheets = getSheets(wb)
  
  # Get state names
  sNames = names(sheets)
  
  # Apply regular expressions and string munipulations to state names
  sNames = tolower(gsub(" ", "", sNames))[-1]
  
  # Import xlsx file into a list
  list = lapply(seq(2, 51), function(x) read.xlsx("countyVotes2008.xlsx", x, header = FALSE)[-1, ])
  
  # Repeat state names to match the county names
  num_of_county = sapply(list, nrow)
  sNames = rep(sNames, num_of_county)
  
  # Get county names
  cNames = unlist(sapply(list, function(x) x[[1]]))
  
  # Apply regular expressions and string munipulations to county names
  cNames = tolower(cNames)
  cNames = gsub(" ", "", cNames)
  cNames = gsub("&", "and", cNames)
  cNames = gsub("county|parish", "", cNames)
  cNames = gsub("\\.", "", cNames)
  
  Obama = as.numeric(as.character(unlist(sapply(list, function(x) x[[4]]))))
  
  Mccain = as.numeric(as.character(unlist(sapply(list, function(x) x[[5]]))))
  
  countyVotes2008 = data.frame(County = cNames, State = sNames, ObamaVote2008 = Obama, MccainVote2008 = Mccain)
  
  ##countyVotes2008 = read.csv("countyVotes2008.csv")
  ##names(countyVotes2008)[c(4,5)] = c("ObamaVote2008", "MccainVote2008")
  ##countyVotes2008 = countyVotes2008[, c(1,2,5,6)]
  
  # EDA of the data
  # Summary Statistics of number of votes for Obama
  summary(countyVotes2008$ObamaVote2008)
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
  #     8    1799    4473   21110   12190 1939000       1 
  
  # Check which county's number of votes for Obama is not available 
  countyVotes2008[which(is.na(countyVotes2008$ObamaVote2008)), ]
  #                          County       State ObamaVote2008
  # 1454 updated:11/10/20083:28pmet mississippi            NA
  #      MccainVote2008
  # 1454             NA
  
  # There is one row of irrelevant information in Mississipi. Drop it from the data frame.
  countyVotes2008 = countyVotes2008[!is.na(countyVotes2008$ObamaVote2008), ]
  
  # The minimum looks a bit bizarre. Check if it is reasonable
  countyVotes2008[which(countyVotes2008$ObamaVote2008 == 8), ]
  
  #      County State ObamaVote2008 MccainVote2008
  # 2629   king texas             8            151
  # The min occurs in King County, Texas. According to Wikipedia, as of the 2010 census, its population was 286, making it the second-least populous county in Texas and the third-least populous of any county in the United States. Plus, the data on Wikipedia shows its vote for Obama is indeed 8. Thus the minimum being 8 makes sense.
  
  # Summary statistics of number of votes for Mccain
  summary(countyVotes2008$MccainVote2008)
  # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  #   67    2867    6243   18540   15850  826500
  # They makes sense
  
  save(countyVotes2008, file = "countyVotes2008.rda")
```

```{r}
  load("countyVotes2008.rda")
```

## Election Results in 2012 (By Jieni Wan)
```{r eval = create2012}
  require(XML)
  # Get state names
  sNames_df = read.csv("http://www.stat.berkeley.edu/users/nolan/data/voteProject/countyVotes2012/stateNames.txt")
  sNames = as.vector(sNames_df$states)
  
  # Since there is no HTTP resource for Alaska, drop it from sNames
  sNames = sNames[sNames != "alaska"]
  
  # Create a vector consisting of all the websites we are going to use
  xml2012 = paste0("http://www.stat.berkeley.edu/users/nolan/data/voteProject/countyVotes2012/", sNames, ".xml")
  
  # Get a list of the xml file of each website
  xmlList = lapply(xml2012, xmlParse)
  
  # Extract the desired information from each xml file, i.e., the number of votes for Obama and Romney, together with the county names
  Obama = lapply(xmlList, function(x) {
    xpathSApply(xmlRoot(x), "//abbr[@title = 'Democratic']/../../td[@class='results-popular']", xmlValue)
  })
  Romney = lapply(xmlList, function(x) {
    xpathSApply(xmlRoot(x), "//abbr[@title = 'Republican']/../../td[@class='results-popular']", xmlValue)
  })
  cNames = lapply(xmlList, function(x) {
    xpathSApply(xmlRoot(x), "/table/tbody/tr/th[@class = 'results-county']", xmlValue)
  })
  
  # Convert the lists to numeric vectors
  ObamaVote2012 = as.numeric(gsub("[, ]", "", unlist(Obama)))
  RomneyVote2012 = as.numeric(gsub("[, ]", "", unlist(Romney)))
  cNames = unlist(cNames)
  
  # Revise the format of the county and state names for merging
  cNames = tolower(cNames)
  cNames = gsub("% reporting", "", cNames)
  cNames = gsub("\\.", "", cNames)
  cNames = gsub(" ", "", cNames)
  cNames = gsub("[0-9]", "", cNames)
  cNames = gsub("county|parish", "", cNames)
  sNames = gsub("-", "", sNames)
  
  # Repeat state names to match county names
  sNames = rep(sNames, sapply(Obama, length))
  
  # Create a data frame with four columns, namely County, State, ObamaVote2012 and RomneyVote2012
  countyVotes2012 = data.frame(County = cNames, State = sNames, ObamaVote2012, RomneyVote2012)
  
  # EDA of the data
  # Summary statistics of number of votes for Obama
  summary(countyVotes2012$ObamaVote2012)
  #  Min.  1st Qu.  Median  Mean   3rd Qu. Max.
  #   5    1552     3945    19860  11090   1672000 

  # NA does not exist, but the minimum is 5, which might be unreasonable

  # Check the minimum to see if it is acceptable
  countyVotes2012[which(countyVotes2012$ObamaVote2012 ==
                          min(countyVotes2012$ObamaVote2012)), ]
  #     County State ObamaVote2012 RomneyVote2012
  #2628   king texas             5            139
 
  # The min occurs in King, Texas. It is acceptable due to previous explanation.

  # Summary statistics of number of votes for Romney
  summary(countyVotes2012$RomneyVote2012)
  # Min.  1st Qu.  Median  Mean   3rd Qu.  Max. 
  # 54    2889     6383    18800  15950    699600 
  # They make sense.
  
  save(countyVotes2012, file = "countyVotes2012.rda")
```

```{r}
  load("countyVotes2012.rda")
```

## Election Results in 2016 (By Victor Choi)
```{r eval = create2016}
  require(readr)
  countyVotes2016 = read.csv("http://www.stat.berkeley.edu/users/nolan/data/voteProject/2016_US_County_Level_Presidential_Results.csv")
  
  # We change all the county names to lower case, remove spaces, substitute & for and, remove periods, remove county or parish
  countyVotes2016$county_name = tolower(countyVotes2016$county_name)
  countyVotes2016$county_name = gsub(" ", "", countyVotes2016$county_name)
  countyVotes2016$county_name = gsub("&", "and", countyVotes2016$county_name)
  countyVotes2016$county_name = gsub("county|parish", "", countyVotes2016$county_name)
  countyVotes2016$county_name = gsub("\\.", "", countyVotes2016$county_name)
  
  # We keep the FIPS, in order to merge with other data sources; we also keep numbers of votes for Clinton and Trump, and the state abbreviations and county names for further data cleaning
  countyVotes2016 = countyVotes2016[, c(10, 9, 2, 3, 11)]
  
  names(countyVotes2016)[c(3, 4)] = c("ClintonVote2016", "TrumpVote2016")

  # EDA of the data
  # Summary Statistics of number of votes for Clinton
  summary(countyVotes2016$ClintonVote2016)
  #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  #      4    1173    3192   20240    9959 1655000
  
  # The minimum number of votes for Clinton is 4, which is extremely small. Check if it is reasonable
  countyVotes2016[which(countyVotes2016$ClintonVote2016 ==
                        min(countyVotes2016$ClintonVote2016)), ]
  #      county_name state_abbr ClintonVote2016 TrumpVote2016 combined_fips
  # 2673      loving         TX               4            57         48301
  # The min occurs in King, Texas. It is acceptable due to the explanation above. 
  
  # Summary statistics of number of votes for Trump
  summary(countyVotes2016$TrumpVote2016)
  # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  #   57    3241    7239   20370   17980  590500
  # They make sense.
  
  save(countyVotes2016, file = "countyVotes2016.rda")
```

```{r}
  load("countyVotes2016.rda")
```

## GML data that contains the latitude and longitude for each county (By Menglu Cao)

  The purpose of GML data is to make an informative map describing the election results on county levels. We will be needing three variables in this data frame, namely the county names, the latitude and longitude for each county.
  
  
```{r eval = CreateGML} 
  require(XML)
  GML = xmlParse("http://www.stat.berkeley.edu/users/nolan/data/voteProject/counties.gml")
  doc = xmlRoot(GML)
  
  # County names
  cNames = as.character(xpathSApply(doc, "//county/gml:name", xmlValue))
  cNames = tolower(cNames)
  cNames = gsub(" ", "", cNames)
  cNames = gsub("&", "and", cNames)
  cNames = gsub("county|parish", "", cNames)
  cNames = gsub("\\.", "", cNames)
  cNames = gsub("\n", "", cNames)
  
  # State names
  sNames = as.character(xpathSApply(doc, "//state/gml:name", xmlValue))
  sNames = tolower(sNames)
  sNames = gsub(" ", "", sNames)
  sNames = gsub("\n", "", sNames)
  
  # Get the number of counties in each state
  num_of_county = xpathSApply(doc, "//state", xmlSize) - 1
  
  # Repeat state names so that they correspond to counties
  sNames = rep(sNames, num_of_county)
  
  # Get the longitude and latitude of counties
  Longitude = as.numeric(xpathSApply(doc, "/doc/state/county/gml:location/gml:coord/gml:X", xmlValue))
  
  Latitude = as.numeric(xpathSApply(doc, "/doc/state/county/gml:location/gml:coord/gml:Y", xmlValue))
  
  # Create a data frame which contain the county names, the correspondent state names, and the latitude and longitude for each county
  GML_df = data.frame(County = cNames, State = sNames, Latitude, Longitude, stringsAsFactors = FALSE)
  
  # Save the intermediate file for efficiency consideration
  save(GML_df, file = "GML.rda")
```

```{r}
load("GML.rda")
```

  We'll then plot the counties by their coordinates to see if the result looks like the map of United States yet without Alaska and Hawaii.
```{r}
# Code by Menglu Cao
require(ggplot2)
ggplot(data = GML_df) +
  geom_point(mapping = aes(x = Longitude, y = Latitude, size = 0.2, alpha = 0.5)) +
  scale_x_continuous(name = "Longitude") +
  scale_y_continuous(name = "Latitude") +
  labs(title = "Map of counties in the United States") +
  theme_bw()
```

  The plot looks right, which means we have properly cleaned the data.
  
## Census data from the 2010 census (BY JOHN TOWEY)
  The census data required that we merge three files together, one with population and race information, one with data on households and family structure, and a third with employment data. We first extract the count of total population from the count of people identitfying as white. We do not extract data on the count of individuals identifying as black, because there are too many counties missing this data. Using the total population and the count of white indidividuals, we derive a percentage of population that is white in each county. 
  We then extract data from the second file on family structures within counties. We look at families with children, rates of single parenthood, seniors living alone, rates of married and never married men, and the average size of families in counties.
  Then we extract employment data, including labor force participation and unemployent rates, female labor force participation and employent rates--which we use to derive female unemployment rates--and employment by occupation and industry.
  After we extract the variabels, we combine them into one data frame and assign a name for counties and states that matches those of the aformentioned data frames--election results data and GML data.
```{r eval = createCensus}
  # POPULATION DATA
  
  B01003 = read.csv("http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/B01003.csv")
  
  # TOTAL POPULATION
  
  totalPopFrame = B01003[B01003$POPGROUP.id == 1, 
                         c("GEO.id2", "GEO.display.label", 
                           "HD01_VD01")] #Frame to extract total population
  totalPopFrame$totalPop = totalPopFrame$HD01_VD01 #1 Generate total population variable
  totalPopFrame = totalPopFrame[ , c("GEO.id2", "GEO.display.label", 
                                     "totalPop")] # Subset to exclude HD01_VD01
  
  # WHITE POPULATION
  
  whitePopFrame = B01003[B01003$POPGROUP.id == 2, 
                         c("GEO.id2", "GEO.display.label", "HD01_VD01")] # Frame to extract white population
  whitePopFrame$whitePop = whitePopFrame$HD01_VD01 #2 Generate white population variable
  whitePopFrame = whitePopFrame[ , c("GEO.id2", "GEO.display.label", 
                                     "whitePop")] # Subset to exclude HD01_VD01
  
  # MERGE INDIVIDUAL POPULATION DATA FILES
  
  populationData = merge(x = totalPopFrame, y = whitePopFrame, 
                         by = c("GEO.id2", "GEO.display.label"),
                         all = TRUE)
  
  # GENERATE PERCENT WHITE VARIABLE
  ## (There are too many missing counties for a black proportion variable, but this allows for comparisons between white/non-white, at least.)
  
  populationData$percentWhite = 
    100 * (populationData$whitePop / populationData$totalPop) #3 White population as a percent of total population
  
  # FAMILY STRUCTURE
  
  DP02 = read.csv("http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/DP02.csv")
  
  # FRAME CONSTRUCTION
  
  familyData = DP02[ , c("GEO.id2", "GEO.display.label",
                         "HC03_VC06", "HC03_VC10", 
                         "HC03_VC12", "HC03_VC15",
                         "HC01_VC21", "HC03_VC36", 
                         "HC03_VC37")]
  
  # VARIABLES
  
  familyData$familiesWithKids = DP02$HC03_VC06 #4 Percent of households that are families with own hildren under 18
  familyData$singleDads = DP02$HC03_VC10 #5 Percent households with a single male head of household with own children under 18
  familyData$singleMoms = DP02$HC03_VC12 #6 Percent of households with a single female head of household with own children under 18
  familyData$seniorsLivingAlone = DP02$HC03_VC15 #7 Housholder living alone, 65 years old or over
  familyData$avgFamilySize = DP02$HC01_VC21 #8 Average size of families
  familyData$neverMarriedMen = DP02$HC03_VC36 #9 Percent of males 15 and older who have never married (not inc. divorced or separated)
  familyData$marriedMen = DP02$HC03_VC37 #10 Percent of males 15 and older who are married (currently married, not inc. separated)
  
  # SUBSET DATA FRAME 
  
  familyData = familyData[ , c(1:2, 10:16)]
  
  # MERGE FAMILY DATA WITH POPULATION DATA
  
  famPopData = merge(x = populationData, y = familyData, 
                     by = c("GEO.id2", "GEO.display.label"),
                     all = TRUE)
  
  
  # EMPLOYMENT DATA
  
  DP03 = read.csv("http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/DP03.csv")
  
  # FRAME CONSTRUCTION
  
  employmentData = DP03[ , c("GEO.id2", "GEO.display.label",
                             "HC03_VC06", "HC03_VC08", 
                             "HC03_VC17", "HC03_VC18",
                             "HC03_VC41", "HC03_VC42", 
                             "HC03_VC50", "HC03_VC51",
                             "HC03_VC52", "HC03_VC54",
                             "HC03_VC58")]
  
  # VARIABLES
  
  # GENERAL EMPLOYMENT
  
  employmentData$laborForce = DP03$HC03_VC06 #11 Labor Force Participation Rate (percent over 16 years old who are employed or unemployed)
  employmentData$unemployed = DP03$HC03_VC08 #12 Unemployment Rate (percent over 16 unemployed)
  employmentData$femaleLaborForce = DP03$HC03_VC17 #13 Female labor force participation rate (percent of females over 16 who are employed or unemployed)
  employmentData$employedWomen = DP03$HC03_VC18 #14 Women over 16 who are employed 
  employmentData$femaleUnemployment = 
    (employmentData$femaleLaborForce - employmentData$employedWomen) #15 Female Unemployment Rate as the difference between the female labor force participation rate and the rate of female employment
  
  # EMPLOYMENT BY OCCUPATION 
  
  employmentData$occManagement = DP03$HC03_VC41 #16 Pecent of the civilian labor force employed in management, business, science, and arts occupations
  employmentData$occService = DP03$HC03_VC42 #17 Percent of the civilian labor force employed in service occupations 
  
  # EMPLOYMENT BY INDUSTRY
  
  employmentData$extractiveIndustries = DP03$HC03_VC50 #18 Percent of the civilian labor force employed in agriculture, forestry, fishing and hunting, and mining industries 
  employmentData$constructionIndustry = DP03$HC03_VC51 #19 Percent of the civilian labor force employed in the construction industry
  employmentData$manufacturingIndustry = DP03$HC03_VC52 #20 Percent of the civilian labor force employed in the manufacturing industry
  employmentData$retailIndustry = DP03$HC03_VC54 #21 Percent of the civilian labor force employed in the retail trade industry
  employmentData$professionalIndustries = DP03$HC03_VC58 #22 Percent of the civilian labor force employed in Professional, scientific, and management, and administrative and waste management services industries
  
  # SUBSET DATA FRAME
  
  employmentData = employmentData[ , c(1:2, 14:25)]
  
  # MERGE EMPLOYMENT DATA WITH POPULATION AND FAMILY DATA
  
  censusData = merge(x = famPopData, y = employmentData, 
                     by = c("GEO.id2", "GEO.display.label"),
                     all = TRUE)
  
  # APPLY REGULAR EXPRESSION AND STRING MANIPULATION TO STATE & COUNTY NAMES
  cNames = as.character(censusData$GEO.display.label)
  cNames = gsub("[- ]", "", cNames)
  cNames = gsub("<", "", cNames)
  cNames = gsub(">", "", cNames)
  cNames = gsub("\\.", "", cNames)
  cNames = tolower(cNames)
  cNames = gsub("county|parish|borough|municipality|municipio|censusarea", "", cNames)
  cNames = gsub("&", "and", cNames)
  
  # SPLIT STATE NAMES AND COUNTY NAMES

  names = strsplit(cNames, split = ",")
  
  # COUNTY NAMES
  cNames = sapply(names, function(x) x[1])

  # ADD COUNTY NAMES TO THE DATA FRAME  
  censusData$County = cNames
  
  # STATE NAMES
  sNames = sapply(names, function(x) x[2])
  
  # ADD STATE NAMES TO THE DATA FRAME
  censusData$State = sNames
  
  names(censusData)[1] = "FIPS"
  censusData = censusData[, -2]
  
  save(censusData, file = "censusData.rda")
```

```{r}
  load("censusData.rda")
```

## Final Merge
At last, we can merge all of the data into one data frame. 
```{r}

```


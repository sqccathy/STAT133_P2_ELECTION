---
title: "Election Project"
Author: Menglu Cao, Jieni Wan, Qichen Sun, John Towey, Victor Choi
output: html_document
---

```{r}
create2004 = FALSE
create2008 = FALSE
create2012 = FALSE
create2016 = FALSE
createGML = FALSE
createCensus = FALSE
```

### STEP 1: DATA WRANGLING

  For convenience in final merging, we create a helper function to apply regular expressions and string manipulations to county names so that they have the same format.
```{r}
# Code by Menglu Cao

cNamesManip = function(cNames) {
  # Convert	all	county names to lower case
  cNames = tolower(cNames)
  # Remove symbols in county names
  cNames = gsub("[ '%]", "", cNames)
  cNames = gsub("-", "", cNames)
  cNames = gsub("\n", "", cNames)
  # Change & to and in county names
  cNames = gsub("&", "and", cNames)
  # Remove redundant characters from county names
  cNames = gsub("county|parish|reporting|municipality|municipio|censusarea", "", cNames)
  # Eliminate	.	from county names
  cNames = gsub("\\.", "", cNames)
  # Remove digits
  cNames = gsub("[0-9]", "", cNames)
}
```


## Election Results in 2004 (By Menglu Cao)

First, read the txt file of election results in 2004 into R.
```{r eval = create2004}
require(readr)
countyVotes2004 = read.delim("http://www.stat.berkeley.edu/~nolan/data/voteProject/countyVotes2004.txt", sep = "")
```

Then add the state names and county names we get to the data frame, countyVotes2004, as new variables. Subset the data frame to extract the information we want, namely, county names, state names, number of votes for Bush and Kerry.
```{r eval = create2004}
# Split state names and county names
names = strsplit(as.character(countyVotes2004$countyName), split = ",")
  
# State names
sNames = sapply(names, function(x) x[1])
  
# Add manipulated state names to the data frame
countyVotes2004$State = tolower(gsub(" ", "", sNames))
  
# County names
cNames = sapply(names, function(x) x[2])
  
# Add county names to the data frame
countyVotes2004$County = cNamesManip(cNames)
  
# Subset countyVotes2004, such that it consists of 4 variables: county names, state names, number of votes for Bush and Kerry
countyVotes2004 = countyVotes2004[, c(5, 4, 2, 3)]
  
# Change variable names in the data frame
names(countyVotes2004)[c(3, 4)] = c("BushVote2004", "KerryVote2004")
```

Notice that data of votes in Virginia are missing. So we scrape those data from HTML tables in Wikipedia and add them to the data frame, countyVotes2004. Names of counties and states should be converted to the same format mentioned above.  
```{r eval = create2004}
# Scrape data of votes in Virginia from HTML tables
require(XML)
require(RCurl)
wikiURL = "https://en.wikipedia.org/wiki/United_States_presidential_election_in_Virginia,_2004"
pageContents = getURLContent(wikiURL)
  
# Set up XPath to find the table
pDoc = htmlParse(pageContents)
pRoot = xmlRoot(pDoc)
cTable = getNodeSet(pRoot, 
          "//table/tr/td/a[@title='Accomack County, Virginia']/../../..")
nrows = xmlSize(cTable[[1]])
  
# Extract Values into Character Matrix
tableChar = do.call(rbind, sapply(1:nrows, function(i) {
                  strsplit(xmlValue(cTable[[1]][[i]]), "\n")}))
  
# Names of counties and the states they belong in Virginia
names = tableChar[-1, 1]
counties = names[!grepl(",", names)]
independentCity = c(sapply(strsplit(names[grepl(",", names)], split = ","), 
                                    function(x) paste0(x[1], "city")))
  
# County names
cNames = cNamesManip(c(counties, independentCity))
  
# Create a character vector consisting of "virginia"
sNames = rep("virginia", length(names))

# Number of votes for Bush & Kerry
BushVote2004 = as.numeric(gsub(",", "", tableChar[-1, 5]))
KerryVote2004 = as.numeric(gsub(",", "", tableChar[-1, 3]))
  
# Create a data frame for Virginia
Virginia2004 = data.frame(County = cNames, State = sNames, BushVote2004, KerryVote2004)
  
# Add data of votes in Virginia to countyVotes2004
countyVotes2004 = rbind(countyVotes2004, Virginia2004)
```

Carry out EDA (Exploratory Data Analysis) to check whether the data are clean or not by referring to summary statistics of the numeber of votes for the two candidates.
```{r eval = create2004}
summary(countyVotes2004$BushVote2004)
```
  
  It turns out that the minimum of votes for Bush is only 65 and the maximum is 1670341, which may not be reasonable. Therefore we find the two rows corresponding to the min and max votes respectively to see the specific locations where the min and max occur. 
```{r eval = create2004}  
countyVotes2004[which(countyVotes2004$BushVote2004 ==
                      min(countyVotes2004$BushVote2004)), ]
```

  The min occurs in Loving, Texas. According to Wikipedia, as of the 2010 census, its population was 82, making it the least populous county in the United States.
```{r eval = create2004}  
countyVotes2004[which(countyVotes2004$BushVote2004 ==                                                 max(countyVotes2004$BushVote2004)), ]
```

  In addition, The max occurs in Los Angeles, California and the 2010 United States Census reported that Los Angeles had a population of 3,792,621. Thus the minimum being 54 and the maximum being 954764 make sense. 
  Similarly, use summary function for the number of votes for Kerry and check whether the minimum and maximum are reasonable.
```{r eval = create2004} 
# Summary statistics of number of votes for Mccain
summary(countyVotes2004$KerryVote2004)
  
# Check if the minimum and maximum are reasonable
countyVotes2004[which(countyVotes2004$KerryVote2004 ==
                      min(countyVotes2004$KerryVote2004)), ]

countyVotes2004[which(countyVotes2004$KerryVote2004 ==                                                max(countyVotes2004$KerryVote2004)), ]
```
  
  The places where the min and max occur are again Loving in Texas and Los Angeles in California, respectively. So they are reasonable as well.
  Then we save the processed data frame as an intermediate file for efficiency consideration.
```{r eval = create2004}
save(countyVotes2004, file = "countyVotes2004.rda")
```

```{r}
load("countyVotes2004.rda")
```


## Election Results in 2008 (BY Qichen Sun)
```{r eval = create2008}
library(xlsx)
wb = loadWorkbook("countyVotes2008.xlsx")
sheets = getSheets(wb)
```  
  
  # Get state names
```{r eval = create2008}
sNames = tolower(gsub(" ", "", names(sheets)))[-1]
```  
  # Import xlsx file into a list
```{r eval = create2008} 
list = lapply(seq(2, 51), function(x) read.xlsx("countyVotes2008.xlsx", x, header = FALSE)[-1, ])
```  
  # Repeat state names to match the county names
```{r eval = create2008}
num_of_county = sapply(list, nrow)
sNames = rep(sNames, num_of_county)
```
  # County names
```{r eval = create2008}
cNames = cNamesManip(unlist(sapply(list, function(x) x[[1]])))
```  
 
```{r eval = create2008}
Obama = as.numeric(as.character(unlist(sapply(list, function(x) x[[4]]))))

Mccain = as.numeric(as.character(unlist(sapply(list, function(x) x[[5]]))))

countyVotes2008 = data.frame(County = cNames, State = sNames, ObamaVote2008 = Obama, MccainVote2008 = Mccain)
```  
  ##countyVotes2008 = read.csv("countyVotes2008.csv")
  ##names(countyVotes2008)[c(4,5)] = c("ObamaVote2008", "MccainVote2008")
  ##countyVotes2008 = countyVotes2008[, c(1,2,5,6)]
  
  # EDA of the data
  # Summary Statistics of number of votes for Obama
```{r eval = create2008}
summary(countyVotes2008$ObamaVote2008)
```
  
  # Check which county's number of votes for Obama is not available 
```{r eval = create2008}
countyVotes2008[which(is.na(countyVotes2008$ObamaVote2008)), ]
```

  
  # There is one row of irrelevant information in Mississipi. Drop it from the data frame.
```{r eval = create2008}
countyVotes2008 = countyVotes2008[!is.na(countyVotes2008$ObamaVote2008), ]
```  
  
  # The minimum looks a bit bizarre. Check if it is reasonable.
```{r eval = create2008}
countyVotes2008[which(countyVotes2008$ObamaVote2008 == 8), ]
```  

  # The min occurs in King County, Texas. According to Wikipedia, as of the 2010 census, its population was 286, making it the second-least populous county in Texas and the third-least populous of any county in the United States. Plus, the data on Wikipedia shows its vote for Obama is indeed 8. Thus the minimum being 8 makes sense.
  
  # Summary statistics of number of votes for Mccain
```{r eval = create2008}
summary(countyVotes2008$MccainVote2008)
```
  # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  #   67    2867    6243   18540   15850  826500
  # They makes sense
  
```{r eval = create2008}
save(countyVotes2008, file = "countyVotes2008.rda")
```

```{r}
load("countyVotes2008.rda")
```

## Election Results in 2012 (By Jieni Wan)

First read txt file into R to create a vector consisting of all the state names. The length of this vector is supposed to be 51 since there are 51 state names in the txt file. However, we find that there is no HTTP resource for Alaska, thus "Alaska" should be dropped from the vector.
```{r eval = create2012}
require(XML)
# Get state names
sNames_df = read.csv("http://www.stat.berkeley.edu/users/nolan/data/voteProject/countyVotes2012/stateNames.txt")
  sNames = tolower(gsub(" ", "", as.vector(sNames_df$states)))
  
# Drop Alaska from sNames
sNames = sNames[sNames != "alaska"]
```

  Notice that the data of votes in 2012 are available at "http://www.stat.berkeley.edu/users/nolan/data/voteProject/countyVotes2012/xxx.xml", where the "xxx" is replaced by the state names. Paste the state names with the same part among the websites to create a new vector containing all the websites we are going to use and then read these xml files into R.

  For each xml file, extract the information we want, i.e., the number of votes for Obama and Romney, together with the county names. Revise the format of county names as stipulated. What's more, since the state names do not exist in the xml files, we need a vector made up by state names to match the relative counties to create a data frame with four columns, namely County, State, ObamaVote2012 and RomneyVote2012. 
```{r eval = create2012}
# Create a vector consisting of all the websites we are going to use
xml2012 = paste0("http://www.stat.berkeley.edu/users/nolan/data/voteProject/countyVotes2012/", sNames, ".xml")
  
# Get a list of the xml file of each website
xmlList = lapply(xml2012, xmlParse)
  
# Extract the desired information from each xml file
Obama = lapply(xmlList, function(x) {
                        xpathSApply(xmlRoot(x), "//abbr[@title =    'Democratic']/../../td[@class='results-popular']", xmlValue)
  })
Romney = lapply(xmlList, function(x) {
                         xpathSApply(xmlRoot(x), "//abbr[@title = 'Republican']/../../td[@class='results-popular']", xmlValue)
  })
cNames = lapply(xmlList, function(x) {
    xpathSApply(xmlRoot(x), "/table/tbody/tr/th[@class = 'results-county']", xmlValue)
  })
  
# Convert the lists to numeric vectors
ObamaVote2012 = as.numeric(gsub("[, ]", "", unlist(Obama)))
RomneyVote2012 = as.numeric(gsub("[, ]", "", unlist(Romney)))
  
# County names
cNames = cNamesManip(unlist(cNames))
  
# Repeat state names to match county names
sNames = rep(sNames, sapply(Obama, length))
  
# Create a data frame with four columns, namely County, State, ObamaVote2012 and RomneyVote2012
countyVotes2012 = data.frame(County = cNames, State = sNames, ObamaVote2012, RomneyVote2012)
```
  
  Next, we carry out EDA to determine what cleaning is necessary, by looking at the summary statistics of the number of votes for Obama.
```{r eval = create2012}
summary(countyVotes2012$ObamaVote2012)
```
  
  It turns out that no NA exists and the values of these statistics of votes for Romney are mostly acceptable, except for the minimal number of votes for Obama is only 5. To check it if makes sense, we need to find the row in which the number of votes for Obama is 5.
```{r eval = create2012}  
countyVotes2012[which(countyVotes2012$ObamaVote2012 ==
                min(countyVotes2012$ObamaVote2012)), ]
```
  
  The min occurs in King, Texas. It is acceptable due to previous explanation.
  Then, we do the same for the number of votes for Romney.
```{r eval = create2012}
summary(countyVotes2012$RomneyVote2012)
``` 

  They also make sense. Then we save the processed data frame as an intermediate file for efficiency consideration.
```{r eval = create2012}
save(countyVotes2012, file = "countyVotes2012.rda")
```

```{r}
load("countyVotes2012.rda")
```

## Election Results in 2016 (By Victor Choi)
```{r eval = create2016}
require(readr)
countyVotes2016 = read.csv("http://www.stat.berkeley.edu/users/nolan/data/voteProject/2016_US_County_Level_Presidential_Results.csv")
  
countyVotes2016$county_name = cNamesManip(countyVotes2016$county_name)
  
# We keep the FIPS, in order to merge with other data sources; we also keep numbers of votes for Clinton and Trump, and the state abbreviations and county names for further data cleaning
countyVotes2016 = countyVotes2016[, c(10, 9, 2, 3, 11)]
  
names(countyVotes2016)[c(3, 4)] = c("ClintonVote2016", "TrumpVote2016")
```

  Next, we carry out EDA to determine what cleaning is necessary, by looking at the summary statistics of the number of votes for Clinton.
```{r eval = create2016}
summary(countyVotes2016$ClintonVote2016)
```

  The minimal number of votes for Clinton is 4, which is unusually small. Check if it is reasonable.
```{r eval = create2016}  
countyVotes2016[which(countyVotes2016$ClintonVote2016 ==
                      min(countyVotes2016$ClintonVote2016)), ]
```
  
  The min occurs in King, Texas. It is acceptable due to the explanation above. 
  We do the same to the number of votes for Trump.
```{r eval = create2016}
summary(countyVotes2016$TrumpVote2016)
```
  
  They make sense. Then we save the processed data frame as an intermediate file for efficiency consideration.
```{r eval = create2016}
save(countyVotes2016, file = "countyVotes2016.rda")
```

```{r}
load("countyVotes2016.rda")
```

## GML data that contains the latitude and longitude for each county (By Menglu Cao)

  The purpose of GML data is to make an informative map describing the election results on county levels. We will be needing four variables in this data frame, namely county names, state names, and the latitude and longitude for each county.
```{r eval = CreateGML} 
require(XML)
GML = xmlParse("http://www.stat.berkeley.edu/users/nolan/data/voteProject/counties.gml")
doc = xmlRoot(GML)
  
# Get county names
cNames = cNamesManip(as.character(xpathSApply(doc, "//county/gml:name", xmlValue)))
  
# Get state names
sNames = as.character(xpathSApply(doc, "//state/gml:name", xmlValue))
sNames = tolower(gsub(" |\n", "", sNames))
 
# Get the number of counties in each state
num_of_county = xpathSApply(doc, "//state", xmlSize) - 1
  
# Repeat state names so that they correspond to counties
sNames = rep(sNames, num_of_county)
  
# Get the longitude and latitude of counties. Note that the coordinates have values in the millions, so we divide them by 10^6 to derive the right values 
Longitude = as.numeric(xpathSApply(doc, "/doc/state/county/gml:location/gml:coord/gml:X", xmlValue)) / 10^6
  
Latitude = as.numeric(xpathSApply(doc, "/doc/state/county/gml:location/gml:coord/gml:Y", xmlValue)) / 10^6
```

  With all the variables needed in position, we can then create a data frame, which contains county names, state names, and the latitude and longitude for each county.
```{r eval = CreateGML} 
GML_df = data.frame(County = cNames, State = sNames, Latitude, Longitude, stringsAsFactors = FALSE)
```

  We'll then plot the counties by their coordinates to see if the result looks like the map of United States.
```{r}
require(ggplot2)
ggplot(data = GML_df) +
  geom_point(mapping = aes(x = Longitude, y = Latitude, size = 0.2, alpha = 0.5)) +
  scale_x_continuous(name = "Longitude") +
  scale_y_continuous(name = "Latitude") +
  labs(title = "Map of counties in the United States") +
  theme_bw()
```

  The plot looks right, which means we have properly cleaned the data. Then we save the intermediate file for efficiency consideration
```{r eval = CreateGML} 
save(GML_df, file = "GML.rda")
```

```{r}
load("GML.rda")
```
  
## Census data from the 2010 census (BY JOHN TOWEY)
  The census data required that we merge three files together, one with population and race information, one with data on households and family structure, and a third with employment data. We first extract the count of total population from the count of people identitfying as white. We do not extract data on the count of individuals identifying as black, because there are too many counties missing this data. Using the total population and the count of white indidividuals, we derive a percentage of population that is white in each county. 
  We then extract data from the second file on family structures within counties. We look at families with children, rates of single parenthood, seniors living alone, rates of married and never married men, and the average size of families in counties.
  Then we extract employment data, including labor force participation and unemployent rates, female labor force participation and employent rates--which we use to derive female unemployment rates--and employment by occupation and industry.
  After we extract the variabels, we combine them into one data frame and assign a name for counties and states that matches those of the aformentioned data frames--election results data and GML data.
```{r eval = createCensus}
  # POPULATION DATA
  
  B01003 = read.csv("http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/B01003.csv")
  
  # TOTAL POPULATION
  
  totalPopFrame = B01003[B01003$POPGROUP.id == 1, 
                         c("GEO.id2", "GEO.display.label", 
                           "HD01_VD01")] #Frame to extract total population
  totalPopFrame$totalPop = totalPopFrame$HD01_VD01 #1 Generate total population variable
  totalPopFrame = totalPopFrame[ , c("GEO.id2", "GEO.display.label", 
                                     "totalPop")] # Subset to exclude HD01_VD01
  
  # WHITE POPULATION
  
  whitePopFrame = B01003[B01003$POPGROUP.id == 2, 
                         c("GEO.id2", "GEO.display.label", "HD01_VD01")] # Frame to extract white population
  whitePopFrame$whitePop = whitePopFrame$HD01_VD01 #2 Generate white population variable
  whitePopFrame = whitePopFrame[ , c("GEO.id2", "GEO.display.label", 
                                     "whitePop")] # Subset to exclude HD01_VD01
  
  # MERGE INDIVIDUAL POPULATION DATA FILES
  
  populationData = merge(x = totalPopFrame, y = whitePopFrame, 
                         by = c("GEO.id2", "GEO.display.label"),
                         all = TRUE)
  
  # GENERATE PERCENT WHITE VARIABLE
  ## (There are too many missing counties for a black proportion variable, but this allows for comparisons between white/non-white, at least.)
  
  populationData$percentWhite = 
    100 * (populationData$whitePop / populationData$totalPop) #3 White population as a percent of total population
  
  # FAMILY STRUCTURE
  
  DP02 = read.csv("http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/DP02.csv")
  
  # FRAME CONSTRUCTION
  
  familyData = DP02[ , c("GEO.id2", "GEO.display.label",
                         "HC03_VC06", "HC03_VC10", 
                         "HC03_VC12", "HC03_VC15",
                         "HC01_VC21", "HC03_VC36", 
                         "HC03_VC37")]
  
  # VARIABLES
  
  familyData$familiesWithKids = DP02$HC03_VC06 #4 Percent of households that are families with own hildren under 18
  familyData$singleDads = DP02$HC03_VC10 #5 Percent households with a single male head of household with own children under 18
  familyData$singleMoms = DP02$HC03_VC12 #6 Percent of households with a single female head of household with own children under 18
  familyData$seniorsLivingAlone = DP02$HC03_VC15 #7 Housholder living alone, 65 years old or over
  familyData$avgFamilySize = DP02$HC01_VC21 #8 Average size of families
  familyData$neverMarriedMen = DP02$HC03_VC36 #9 Percent of males 15 and older who have never married (not inc. divorced or separated)
  familyData$marriedMen = DP02$HC03_VC37 #10 Percent of males 15 and older who are married (currently married, not inc. separated)
  
  # SUBSET DATA FRAME 
  
  familyData = familyData[ , c(1:2, 10:16)]
  
  # MERGE FAMILY DATA WITH POPULATION DATA
  
  famPopData = merge(x = populationData, y = familyData, 
                     by = c("GEO.id2", "GEO.display.label"),
                     all = TRUE)
  
  
  # EMPLOYMENT DATA
  
  DP03 = read.csv("http://www.stat.berkeley.edu/~nolan/data/voteProject/census2010/DP03.csv")
  
  # FRAME CONSTRUCTION
  
  employmentData = DP03[ , c("GEO.id2", "GEO.display.label",
                             "HC03_VC06", "HC03_VC08", 
                             "HC03_VC17", "HC03_VC18",
                             "HC03_VC41", "HC03_VC42", 
                             "HC03_VC50", "HC03_VC51",
                             "HC03_VC52", "HC03_VC54",
                             "HC03_VC58")]
  
  # VARIABLES
  
  # GENERAL EMPLOYMENT
  
  employmentData$laborForce = DP03$HC03_VC06 #11 Labor Force Participation Rate (percent over 16 years old who are employed or unemployed)
  employmentData$unemployed = DP03$HC03_VC08 #12 Unemployment Rate (percent over 16 unemployed)
  employmentData$femaleLaborForce = DP03$HC03_VC17 #13 Female labor force participation rate (percent of females over 16 who are employed or unemployed)
  employmentData$employedWomen = DP03$HC03_VC18 #14 Women over 16 who are employed 
  employmentData$femaleUnemployment = 
    (employmentData$femaleLaborForce - employmentData$employedWomen) #15 Female Unemployment Rate as the difference between the female labor force participation rate and the rate of female employment
  
  # EMPLOYMENT BY OCCUPATION 
  
  employmentData$occManagement = DP03$HC03_VC41 #16 Pecent of the civilian labor force employed in management, business, science, and arts occupations
  employmentData$occService = DP03$HC03_VC42 #17 Percent of the civilian labor force employed in service occupations 
  
  # EMPLOYMENT BY INDUSTRY
  
  employmentData$extractiveIndustries = DP03$HC03_VC50 #18 Percent of the civilian labor force employed in agriculture, forestry, fishing and hunting, and mining industries 
  employmentData$constructionIndustry = DP03$HC03_VC51 #19 Percent of the civilian labor force employed in the construction industry
  employmentData$manufacturingIndustry = DP03$HC03_VC52 #20 Percent of the civilian labor force employed in the manufacturing industry
  employmentData$retailIndustry = DP03$HC03_VC54 #21 Percent of the civilian labor force employed in the retail trade industry
  employmentData$professionalIndustries = DP03$HC03_VC58 #22 Percent of the civilian labor force employed in Professional, scientific, and management, and administrative and waste management services industries
  
  # SUBSET DATA FRAME
  
  employmentData = employmentData[ , c(1:2, 14:25)]
  
  # MERGE EMPLOYMENT DATA WITH POPULATION AND FAMILY DATA
  
  censusData = merge(x = famPopData, y = employmentData, 
                     by = c("GEO.id2", "GEO.display.label"),
                     all = TRUE)
  
  # STATE & COUNTY NAMES
  cNames = as.character(censusData$GEO.display.label)
  cNames = gsub(' ', "", cNames)
  
  # SPLIT STATE NAMES AND COUNTY NAMES

  names = strsplit(cNames, split = ",")
  
  # ADD COUNTY NAMES TO THE DATA FRAME
  
  censusData$County = cNamesManip(sapply(names, function(x) x[1]))

  # ADD STATE NAMES TO THE DATA FRAME
    
  censusData$State = tolower(gsub(" ", "", sapply(names, function(x) x[2])))
  
  names(censusData)[1] = "FIPS"
  censusData = censusData[, -2]
  
  save(censusData, file = "censusData.rda")
```

```{r}
  load("censusData.rda")
```


## Final Merge
At last, we can merge all of the data into one data frame. 
#By Victor Choi
```{r}
merge0812 = merge(countyVotes2012,countyVotes2008, by = c("County", "State"), all = TRUE)

merge0812[which(!complete.cases(merge0812)), ]
```

We find that the 2008 data does not contain data for District of Columbia, so we decide to code it in.
We also find that 2012 data does not contain data for Alaska, so we decided to remove the row.

```{r}
merge0812[which(merge0812$County == "districtofcolumbia"), c(5,6)] = c(245800, 17367)
merge0812 = merge0812[(which(!merge0812$County %in% c("alaska"))), ]

finalDataFrame = merge0812
```

```{r}
mergecensus16 = merge(countyVotes2016, censusData, by.x = "combined_fips", by.y = "FIPS", all = TRUE)

mergecensus16[which(is.na(mergecensus16$ClintonVote2016)), ]
mergecensus16[which(is.na(censusData$County)), ]
```

We find that in the 2016 data, there is no data for Puerto Rico. As in the other data sets there is also no data for Puerto Rico, we decide to take it out.
We also find that data for Bedford City is missing in 2016. Upon further research, we find that in 2013 Bedford City became no longer an independent city, thus, there is no "Bedford City" in the 2016 data. We decided to leave the NAs for now.

We also decide to take out the State Abbreviation column, for clarity.


```{r}
mergecensus16 = mergecensus16[(which(!mergecensus16$State.y == c("puertorico"))), ]
mergecensus16 = mergecensus16[ ,!(names(mergecensus16) == "State.x")]
names(mergecensus16)[28] = "State"
```

```{r}
merge0812c16 = merge(merge0812, mergecensus16, by.x = c("County", "State"), by.y = c("County.x", "State"), all =TRUE)
merge0812c16[which(is.na(merge0812c16$ClintonVote2016)), ]
```


## REFERENCES

Adrian A. Dragulescu (2014). xlsx: Read, write, format Excel 2007 and
  Excel 97/2000/XP/2003 files. R package version 0.5.7.
  https://CRAN.R-project.org/package=xlsx

Duncan Temple Lang and the CRAN Team (2016a). XML: Tools for Parsing and
  Generating XML Within R and S-Plus. R package version 3.98-1.4.
  https://CRAN.R-project.org/package=XML
  
Duncan Temple Lang and the CRAN team (2016b). RCurl: General Network
  (HTTP/FTP/...) Client Interface for R. R package version 1.95-4.8.
  https://CRAN.R-project.org/package=RCurl

Hadley Wickham, Jim Hester and Romain Francois (2016). readr: Read
  Tabular Data. R package version 1.0.0.
  https://CRAN.R-project.org/package=readr

R Core Team (2016). R: A language and environment for statistical
  computing. R Foundation for Statistical Computing, Vienna, Austria. URL
  https://www.R-project.org/.

United States presidential election in Texas, 2008
https://en.wikipedia.org/wiki/United_States_presidential_election_in_Texas,_2008
